---
title: "Experiment 2: Methods & Results"
format: html
editor: visual
embed-resources: TRUE
editor_options: 
  chunk_output_type: console
---

```{r options, include = FALSE}
knitr::opts_chunk$set(
  eval = TRUE,
  echo = FALSE,
  output = TRUE,
  warning = FALSE,
  error = FALSE,
  message = FALSE,
  collapse = TRUE
)
```

```{r setup}
pacman::p_load_gh("GidonFrischkorn/AntiSaccade")
pacman::p_load(papaja, here, lavaan, brms, dplyr, ggplot2)
options(mc.cores = parallel::detectCores())

# plot settings
plot_dodge <- 1
jitter_width <- 1
point_alpha <- 0.1
```

# Methods

In this study, we again isolated different processes contributing to performance in the manual anti saccade task. We added another condition to more directly isolate procedural binding strength and additionally, we measured individual differences in working memory capacity (WMC) and processing speed (PS) to investigate which of the processes required in the manual anti-saccade task was related to PS and WMC.

```{r load_data, include=FALSE}
data <- Exp2_data %>% filter(CTI != 200)
nSub_total <- length(unique(data$ID))
data$CTI_num <- (data$CTI)/1000
data$CTI <- as.factor(data$CTI)
data$FixDur_num <- (data$FixDur - mean(unique(data$FixDur)))/1000

data$RTms <- data$RTms + 150

inhib_blocks <- c("Anti","Random")
bind_blocks <- c("Pro","Anti","Colour")
bottomup_blocks <- c("No","Pro")
saccade_blocks <- c("Pro","Anti","Random","Central")
bind_arbitraty <- c("Colour")

Block2Conds <- data.frame(
  Block = unique(data$Block)
)

data$inhibition <- ifelse(data$Block %in% inhib_blocks, 1, 0)
data$binding <- ifelse(data$Block %in% bind_blocks, 1, 0)
data$bottomup <- ifelse(data$Block %in% bottomup_blocks, 1, 0)
data$saccade <- ifelse(data$Block %in% saccade_blocks, 1, 0)
data$bindArb <- ifelse(data$binding == 0, 0,
                       ifelse(data$Block %in% bind_arbitraty, -1,1))

Block2Conds$inhibition <- ifelse(Block2Conds$Block %in% inhib_blocks,1, 0)
Block2Conds$binding <- ifelse(Block2Conds$Block %in% bind_blocks, 1, 0)
Block2Conds$bottomup <- ifelse(Block2Conds$Block %in% bottomup_blocks, 1, 0)
Block2Conds$saccade <- ifelse(Block2Conds$Block %in% saccade_blocks, 1, 0)
Block2Conds$bindArb <- ifelse(Block2Conds$binding == 0, 0,
                              ifelse(Block2Conds$Block %in% bind_arbitraty, -1,1))

outlier_data <- data %>% 
  group_by(ID, Block, CTI) %>% 
  summarise(meanPC = mean(correct),
            nTrials = n(),
            .groups = "drop") %>% 
  group_by(Block,CTI) %>% 
  mutate(
    meanPC_logit = logit_scaled(meanPC - (0.5/nTrials)),
    zPC_logit = (meanPC_logit - mean(meanPC_logit))/sd(meanPC_logit))
outlier_IDs2 <- unique(outlier_data$ID[which(outlier_data$meanPC <= qbinom(p = .99, size = outlier_data$nTrials, prob = 1/3)/outlier_data$nTrials)])
outlier_IDs <- unique(outlier_data$ID[which(outlier_data$zPC_logit <= qnorm(p = .01))])

data <- data %>% 
  filter(!ID %in% outlier_IDs)
nSub <- length(unique(data$ID))

agg_data <- data %>%
  dplyr::group_by(ID, Block, bottomup, saccade, inhibition, binding, bindArb, FixDur, FixDur_num, CTI, CTI_num) %>%
  dplyr::summarise(
    correct = sum(correct),
    nTrials = dplyr::n(),
    .groups = "drop"
  )
```

## Participants

We recruited `r papaja::printnum(nSub_total)` participants via Prolific, `r papaja::printnum(nSub_total - nSub)` participants were excluded for low performance, thus `r papaja::printnum(nSub)` participants were included in the data analyses. Participants were required to be 18 to 40 years old, speak English as their first language, and have an approval rate of at least 85% when participating in studies on Prolific.

## Tasks

All tasks were again programmed in lab.js (Henninger et al., 2020) and run via JATOS. The tasks were run locally on the participants machines, but we required that the a laptop or desktop computer was used.[^1] Participation using a tablet or smartphone was not allowed. All tasks were run in a single session that lasted approximately 90 to 100 minutes. In between tasks participants were allowed to take breaks. For all participants the session started with the manual saccade task, followed by switching between one of the working memory task and processing task until all tasks were completed.

[^1]: In the supplementary experiment 6 (S6), we investigated if experimental manipulations in the manual anti-saccade task are comparable when performing it on a laptop and desktop computer. The results indicated that there were no differences in the experimental effects. Our goal with this study was to investigate to what extend differences in the devices used could impact the experimental effects as well as individual differences in the manual anti-saccade task.

### Saccade Task

In addition, to the five experimental blocks implemented in the previous experiment, we included a Color Saccade block in this experiment. In the Color Saccade block the cue appeared in the center of the screen and had one of four potential colors: red, blue, green, or yellow. Each color was associated with one of the four peripheral locations the target could appear in (red = on the right from the center, blue = below the center, green = above the center, and yellow = left of the center). Thus, this block did not require to inhibit an automatic saccade as the cue appeared in the center of the screen, but the cue color was associated with the location the target would appear in. To facilitate the recognition of the cue color, we changed the cue stimulus from an equal sifn ("=") to a color patch. In the Color Saccade block the color path was either red, blue, green, or yellow. In all other blocks the color patch was black. An overview of the processes required in the six experimental blocks in the saccade experiment is shown in @tbl-Block2Proc

```{r Blocks2Procs}
#| label: tbl-Block2Proc
#| tab-cap: "Processes required by the different experimental blocks."
Table_Blocks2Procs <- Block2Conds %>% 
  mutate(PercSpeed = 1) %>% 
  select(Block, PercSpeed, inhibition, binding, saccade, bottomup)

Table_Blocks2Procs[,2:6] <- ifelse(Table_Blocks2Procs[,2:6] == 1, "yes","no")
Table_Blocks2Procs <- Table_Blocks2Procs[c(3,2,5,1,6,4),]
colnames(Table_Blocks2Procs) <- c("Block", "Perceptual Speed", "Inhibition", "Binding", "Saccade", "Bottom Up")
knitr::kable(Table_Blocks2Procs)
```

We again varied the Cue-Traget Innterval, but only in two levels[^2]: 50 and 400ms to evaluate if longer time to inhibit automatic saccades towards the cued-location and useing the location or color of the cue to perform a controlled saccade improves performance. Otherwise, the trial procedure was identical to the first experiment, except that the fixation duration was varied from 200ms to 1800ms in steps of 400ms. Accordingly, in each block we ran 120 trials, so that each of the three target letters, appeared once in each of the four peripheral locations with each of the five fixation durations and two CTIs. For each trial, we again recorded the response given as well as the response time as the time between onset of the target stimulus until the response.

[^2]: We dropped one CTI condition to reduce testing time.

We also noticed, that in the first experiment performance was better (Average PC around 80% in Anti-Saccade and 95% in Pro-Saccade trials at the shortest CTI) than in previous studies using the manual Anti-Saccade task (Average PC around 50% in Anti-Saccade and 95% in Pro-Saccade trials). Therefore, we adapted the font size of the stimuli to more closely match the average performance in previous studies. For this we ran two additional supplementary experiments S4 and S5 that are reported in the online supplementary material. Finally, we also evaluated if differences in Screen sizes might contribute to individual differences in the experimental effects and compared if completing the task on a laptop with a small screen compared to a lab computer with a large screen changed the size of effects in the different experimental blocks. This was not the case as can be seen from the results of experiment S7 reported in the supplementary material.

### Working Memory Tasks

```{r Prep_WMCdata}
data_WMC <- Exp2_WMC_data

# extract PCA scores for WMC
data_CS_proc <- Exp2_WMC_data %>% 
  filter(task == "CS processing")

nSub_CS_total <- length(unique(data_CS_proc$ID))

# filter participants that did processing in CS task correctly
data_CS_nonResp <- data_CS_proc %>% 
  group_by(ID, retPos) %>% 
  summarise(sdRT = sd(RTms),
            meanRT = mean(RTms),
            nMiss = sum(is.na(correct)),
            nCorrect = sum(correct, na.rm = T),
            nTrials = n(),
            meanPC = nCorrect/nTrials
  ) %>% 
  filter(meanPC > .70)
use_CS_IDs <- names(table(data_CS_nonResp$ID))[table(data_CS_nonResp$ID) == 2]

nSub_CS <- length(use_CS_IDs)

missing_CS <- (1 - (nSub_CS/nSub_CS_total))*100

aggData_WMC <- data_WMC %>% 
  filter(task != "CS processing", task != "CS") %>% 
  group_by(ID,task,trialNum) %>% 
  summarise(meanPC = mean(correct),
            nCor = sum(correct),
            nRet = n(),
            setsize = mean(setsize)) %>% 
  summarise(meanPC = mean(meanPC),
            nRet = n())
aggData_WMC$task <- as.factor(aggData_WMC$task)
levels(aggData_WMC$task) <- c("Col. Bind.", "Num. Upd.")

plotDesc_WMC <- ggplot(aggData_WMC,
                       aes(y = meanPC, x = task, color = task)) +
  stat_summary() +
  geom_jitter(alpha = 0.2) +
  labs(y = "Proportion Correct", x = "Task", color = "Task") +
  theme_bw() +
  theme(panel.grid.major.x = element_blank(),
        legend.position = "none")

ggsave(filename = "figures_E2/E2_Descriptives_WMC.jpg",plotDesc_WMC, dpi = 300, width = 4, height = 4)

aggData_WMC <- data_WMC %>% 
  filter(task != "CS processing", task != "CS") %>% 
  group_by(ID,task,trialNum) %>% 
  summarise(meanPC = mean(correct),
            nCor = sum(correct),
            nRet = n(),
            setsize = mean(setsize)) %>% 
  summarise(meanPC = mean(meanPC),
            nRet = n()) %>% 
  select(-nRet) %>% 
  tidyr::pivot_wider(names_from = c(task),
                     values_from = meanPC)

aggData_WMC$nTaskMissing <- rowSums(is.na(aggData_WMC[,2:3]))

aggData_WMC <- aggData_WMC %>% 
  filter(nTaskMissing < 1)
```

#### Color-Location Binding

In the color-location binding task, participants were asked to remember in which position in a 4x4 grid different color patches were presented in. The number of to-be-remembered color patches varied from 3 to 5. Each color was shown for 1 second with an inter-stimulus interval of 1 second until the next color was shown. After all colors were shown and a short retention interval of 1 second, all items were tested sequentially in random order. For this, either a cue appeared in one of the locations and participants needed to select which out of the 8 colors used in the task was presented in the cued-location or a color was shown below the 4x4 grid and participants had to select in which position the color was shown in. There were 6 trials in each set size with 3 using location and 3 colors as retrieval cues.

Performance was measured by calculating the proportion correct in each trial and then aggregating it over all trials, irrespective of set size and retrieval type.

#### Number Updating

In the number updating task, participants saw 3 to 5 digits in different locations of a 4x4 grid. They were instructed to remember these digits at the location they were presented in. After all digits have were presented there were 3 updating steps. In each updating step a transformation (+/- 1 or 2) was shown in one of locations a digit was presented in. Participants were instructed to perform this transformation and remember its result at the respective location. After 3 random digits have been updated, all items were tested in random order by sequentially cueing one of the locations in the 4x4 grid in which items were presented and asking participants to enter the digit they remembered in this position on the number pad.

As in the color-location binding task, each digit or transformation was presented for one second with an inter-stimulus interval of one second. Retrieval started after all encoding and transformation steps were finished with a short retention interval of one second. There were 7 trials in each set size, and performance was measured by first calculating the proportion correct in each trial and then aggregating it over all trials irrespective of set size.

#### Letter Complex Span

In the letter complex span task, participants saw 3 to 5 green letters in different locations of a 4x4 grid. They were instructed to remember these letters at the location they were presented in. Interleaving the green letters, red letters were shown as distractors. To ensure that memory items (green letters) and distractors (red letters) were sufficiently processed, participants had to judge for each letter either if it was located on the left or right of the grid, or the letter was a vowel or consonant. For this, they were instructed to respond with the left and right arrow key for the location judgement and the up and down arrow key for the consonant/vowel judgement.

Participants were informed about which processing task to perform in the current trial at the beginning of each trial. Then all memory items and distractors were shown sequentially. The letters were presented for 1.5 seconds with a 1 second inter-stimulus interval between memory items and distractors. The processing task needed to be performed while the letters were on screen. Then after all letters and distractors were shown, all memory items were tested. As in the Color-Location Binding task, participants were either cued by location and had to type the letter they remembered in this position, or were cued with a letter and had to click on the position they remembered the letter in in the 4x4 grid. There were 4 trials in each set size crossing the retrieval cue and processing task for each set size.

We discarded subjects that did not perform the processing task or were below 70% accuracy. Unfortunately, `r printnum(round(missing_CS,2))`% of subjects did not pass the threshold of adequately performing the processing task and responding at least 70% correct. Given this large proportion of subject data that cannot be used, we decided to not include the complex span task in our analyses. In particular, because any method for dealing with these missing values would have to assume that they are missing at random, which they are clearly not in this case.

### Processing Speed Tasks

```{r Prep_PSdata}
# load data of covariates
data_PS <- Exp2_PS_data

data_HT <- Exp2_PS_data %>% 
  filter(task == "HT")
data_HT_outlier <- data_HT %>% 
  mutate(outlier_RT = case_when(RTms < 50 ~ "fast",
                                RTms > 5000 ~ "slow",
                                is.na(correct) ~ "miss",
                                TRUE ~ "no")) %>% 
  group_by(ID,task, taskDiff, outlier_RT) %>%
  summarise(nOutlier = n()) %>% 
  tidyr::pivot_wider(names_from = outlier_RT,
                     values_from = nOutlier) 
data_HT_outlier[is.na(data_HT_outlier)] <- 0

data_HT_outlier <- data_HT_outlier %>% 
  mutate(nTrials = no + fast + slow + miss,
         propValid = no/nTrials,
         discard = ifelse(propValid < .80, "yes","no")) %>% 
  filter(discard == "yes")

ID_HT_outlier <- unique(data_HT_outlier$ID)

data_HT_clean <- data_HT %>% 
  filter(!ID %in% ID_HT_outlier)

data_CJ <- Exp2_PS_data %>% 
  filter(task == "CJ")

data_CJ_outlier <- data_CJ %>% 
  mutate(outlier_RT = case_when(RTms < 50 ~ "fast",
                                RTms > 5000 ~ "slow",
                                is.na(correct) ~ "miss",
                                TRUE ~ "no")) %>% 
  group_by(ID,task, taskDiff, outlier_RT) %>%
  summarise(nOutlier = n()) %>% 
  tidyr::pivot_wider(names_from = outlier_RT,
                     values_from = nOutlier) 
data_CJ_outlier[is.na(data_CJ_outlier)] <- 0

data_CJ_outlier <- data_CJ_outlier %>% 
  mutate(nTrials = no + fast + slow,
         propValid = no/nTrials,
         discard = ifelse(propValid < .80, "yes","no")) %>% 
  filter(discard == "yes")

ID_CJ_outlier <- unique(data_CJ_outlier$ID)

data_CJ_clean <- data_CJ %>% 
  filter(!ID %in% ID_CJ_outlier)

data_NJ <- Exp2_PS_data %>% 
  filter(task == "NJ")

data_NJ_outlier <- data_NJ %>% 
  mutate(outlier_RT = case_when(RTms < 50 ~ "fast",
                                RTms > 5000 ~ "slow",
                                is.na(correct) ~ "miss",
                                TRUE ~ "no")) %>% 
  group_by(ID,task, taskDiff, outlier_RT) %>%
  summarise(nOutlier = n()) %>% 
  tidyr::pivot_wider(names_from = outlier_RT,
                     values_from = nOutlier) 
data_NJ_outlier[is.na(data_NJ_outlier)] <- 0

data_NJ_outlier <- data_NJ_outlier %>% 
  mutate(nTrials = no + fast + slow,
         propValid = no/nTrials,
         discard = ifelse(propValid < .80, "yes","no")) %>% 
  filter(discard == "yes")

ID_NJ_outlier <- unique(data_NJ_outlier$ID)

data_NJ_clean <- data_NJ %>% 
  filter(!ID %in% ID_NJ_outlier)

data_PS_clean <- rbind(data_HT_clean, data_CJ_clean, data_NJ_clean)

prop_removed_PS <- (1 - nrow(data_PS_clean %>% filter(RTms > 50, RTms < 5000, !is.na(correct))) / nrow(data_PS_clean)) * 100

aggData_PS <- data_PS_clean %>% 
  filter(RTms > 50, RTms < 5000, !is.na(correct)) %>% 
  mutate(RT = RTms/1000,
         accuracy = ifelse(correct, 1, 0)) %>%  
  group_by(ID, task) %>% 
  summarise(v = ez.dm(RT = RT, ACC = accuracy, robust = TRUE)[1],
            a = ez.dm(RT = RT, ACC = accuracy, robust = TRUE)[2],
            t0 = ez.dm(RT = RT, ACC = accuracy, robust = TRUE)[3]) 
aggData_PS$task <- as.factor(aggData_PS$task)
levels(aggData_PS$task) <- c("Col. Judg.", "Choice RT", "Num. Judg.")

plotDrift_PS <- ggplot(data = aggData_PS,
                       aes(x = task, y = v, color = task)) +
  stat_summary(position = position_dodge(plot_dodge)) +
  geom_jitter(alpha = 0.2, position = ggplot2::position_jitterdodge(jitter.width = jitter_width, dodge.width = plot_dodge)) +
  labs(y = "Drift Rate", x = "Task", color = "Task") +
  theme_bw() +
  theme(panel.grid.major.x = element_blank(),
        legend.position = "none")


aggData_PS_acc <- data_PS_clean %>% 
  filter(RTms > 50, RTms < 5000, !is.na(correct)) %>% 
  mutate(RT = RTms/1000,
         accuracy = ifelse(correct, 1, 0)) %>%  
  group_by(ID, task) %>% 
  summarise(meanPC = mean(accuracy))

plotACC_PS <- ggplot(data = aggData_PS_acc,
                     aes(x = task, y = meanPC, color = task)) +
  stat_summary(position = position_dodge(plot_dodge)) +
  geom_jitter(alpha = 0.2, position = ggplot2::position_jitterdodge(jitter.width = 0.25, dodge.width = plot_dodge)) +
  labs(y = "Proportion Correct", x = "Task Difficulty", color = "Task") +
  geom_hline(yintercept = 0.5, color = "red", linetype = "dashed") +
  theme_bw() +
  theme(panel.grid.major.x = element_blank(),
        legend.position = "none")

aggData_PS_rt <- data_PS_clean %>% 
  filter(RTms > 50, RTms < 5000, !is.na(correct)) %>% 
  mutate(RT = RTms/1000,
         accuracy = ifelse(correct, 1, 0)) %>%
  filter(accuracy == 1) %>% 
  group_by(ID, task) %>% 
  summarise(meanRT = mean(RT)) 

plotRT_PS <- ggplot(data = aggData_PS_rt,
                    aes(x = task, y = meanRT, color = task)) +
  stat_summary(position = position_dodge(plot_dodge)) +
  geom_jitter(alpha = 0.2, position = ggplot2::position_jitterdodge(jitter.width = 0.25, dodge.width = plot_dodge)) +
  labs(y = "Mean Reaction Time (in s)", x = "Task Difficulty", color = "Task") +
  theme_bw() +
  theme(panel.grid.major.x = element_blank(),
        legend.position = "none")

ggsave(filename = "figures_E2/E2_Descriptives_PSdrift.jpg",plotDrift_PS, dpi = 300, width = 4, height = 4)
ggsave(filename = "figures_E2/E2_Descriptives_PSrt.jpg",plotRT_PS, dpi = 300, width = 4, height = 4)
ggsave(filename = "figures_E2/E2_Descriptives_PSacc.jpg",plotACC_PS, dpi = 300, width = 4, height = 4)

aggData_PS <- data_PS_clean %>% 
  filter(RTms > 50, RTms < 5000, !is.na(correct)) %>% 
  mutate(RT = RTms/1000,
         accuracy = ifelse(correct, 1, 0)) %>%  
  group_by(ID, task) %>% 
  summarise(v = ez.dm(RT = RT, ACC = accuracy, robust = TRUE)[1],
            a = ez.dm(RT = RT, ACC = accuracy, robust = TRUE)[2],
            t0 = ez.dm(RT = RT, ACC = accuracy, robust = TRUE)[3])  %>% 
  tidyr::pivot_wider(names_from = c(task),
                     values_from = c(v,a,t0))

aggData_PS$nTaskMissing <- rowSums(is.na(aggData_PS[,2:10]))

aggData_PS <- aggData_PS %>% 
  filter(nTaskMissing <= 3)
```

#### Color Judgement

In the color judgement (CJ) task, participants saw a 10x10 grid of black and white tiles and were instructed to decide if there were more black or white tiles in the grid. The difficulty of the decision was varied from easy (55 % black or white), to medium (53% black or white), and hard (51% black or white). Participants responded by pressing the left and right arrow keys to indicate if they detected more black or white tiles.

Each trial of this task started with a fixation cross shown for 600 ms in the center of the screen. Then the 10x10 grid with black and white tiles was shown until participants responded. Then, after an inter-trial interval of 1200 ms, the next trial started. There were 34 trials per difficulty level. We analyzed both reaction times and proportion correct using the ez-Diffusion Model and used drift rate (v) as an indicator for processing speed.

#### Number Judgement

In the number judgement (NJ) task, participants saw two digits left and right from the center of the screen and had to decide which of the two was larger. The difficulty of the decision varied from easy (difference = 3), to medium (difference = 2), and hard (difference = 1). Participants responded by pressing the left or right arrow key to indicate which digit was larger.

As for the Color Judgement task, each trial started with a fixation cross shown for 600 ms in the center of the screen. Then the two digits appeared left and right of the fixation cross and stayed on screen until participants responded. Then, after an inter-trial interval of 1200 ms, the next trial started. There were 36 trials in each difficulty level. We analyzed both reaction times and proportion correct using the ez-Diffusion Model and used drift rate (v) as an indicator for processing speed.

#### Choice Reaction Task

In the choice reaction task (CRT), participants saw one, two, or four boxes left, right, above, or below the center of the screen. Then, a "\#" appeared in one of the boxes and they had to press the corresponding arrow key. The difficulty varied through showing one box (easy), two boxes (medium), or four boxes (hard). This was designed following the principles of the classical Hick task varying the potential number of choices, participants have to select a response from.

Again, the trial started with a fixation cross shown for 400 ms. Then either one, two, or four boxes appeared to mark in which positions the target could appear in were shown. After 800 to 1200 ms a "\#" appeared in one of the boxes and participants had to press the corresponding arrow key as fast as possible.[^3] Then, after a short inter-trial interval shown for 800 ms, the next trial started. There were 32 trials in each difficulty level. We analyzed both reaction times and proportion correct using the ez-Diffusion Model and used drift rate (v) as an indicator for processing speed.

[^3]: Due to a programming error there was a response deadline of 1000 ms. But as the number of missed responses was very low (\< .5%) we decided to include this task in the analyses.

## Data Analysis

```{r include=FALSE}
n_full <- nrow(data)
data <- data %>% filter(RTms > 150, RTms < 5000)
n_filter <- nrow(data)

prop_filter <- (1 - n_filter/n_full) * 100
```

Prior to data analysis we removed trials with reaction times shorter than 150 ms and longer than 5000ms in the manual saccade task and reaction times shorter than 50md and longer than 5000 ms in all reaction time tasks. This resulted in discarding `r papaja::printnum(prop_filter)`% of data in the manual saccade task, and `r papaja::printnum(prop_removed_PS)`% in the processing speed tasks.

# Manual Saccade Experiment

In the Manual Saccade Experiment, we again analyzed the number of correct responses with a Bayesian Generalized Linear Model assuming the number of correct responses follows a binomial distribution. Like for Experiment 1, we used a logit link function estimating the linear model on the logit-scale. The model was estimated using the R package `brms`.

```{r model_family}
model_family <- brmsfamily("binomial", link = "logit")
```

We also estimated the same theoretically motivated model separating the different processes contributing to performance in the Saccade Task. The goal of this study was to investigate which of these processes was related to individual differences in working memory capacity and processing speed. Therefore we additionally predicted the different processes by working memory capacity and processing speed. For this, we separately entered either working memory capacity or processing speed as a predictor of the different processes into the GLM model. In addition, we extracted the subject estimates of the different processes from the GLM without entering either working memory capacity and processing speed as a predictor and then correlated these with working memory capacity and intelligence.

```{r LinearModel}
model_sat <- bf(correct | trials(nTrials) ~ 
                  # fixed effects
                  0 + Block + Block:CTI_num + 
                  # random effects
                  (0 + Block + Block:CTI_num | ID))

model_th_full <- bf(correct | trials(nTrials) ~ PercSpeed - 
                      inhibition * (InhibPro * exp(-exp(InhibReac)*CTI_num)) + 
                      binding * ((bindingAct + bindArb * arbBind) * CTI_num) +
                      bottomup * capture +
                      saccade * saccReq +
                      goalMain * FixDur_num,
                    PercSpeed  ~ 1 + (1 | r | ID),
                    goalMain   ~ 1 + (1 | r | ID),
                    capture    ~ 1 + (1 | r | ID),
                    saccReq    ~ 1 + (1 | r | ID),
                    InhibPro   ~ 1 + (1 | r | ID),
                    InhibReac  ~ 1 + (1 | r | ID),
                    bindingAct ~ 1 + (1 | r | ID),
                    arbBind    ~ 1 + (1 | r | ID),
                    nl = TRUE)

model_th_noPercSD <- bf(correct | trials(nTrials) ~ PercSpeed - 
                          inhibition * (InhibPro * exp(-exp(InhibReac)*CTI_num)) + 
                          binding * ((bindingAct + bindArb * arbBind) * CTI_num) +
                          bottomup * capture +
                          saccade * saccReq +
                          goalMain * FixDur_num,
                        PercSpeed  ~ 1,
                        goalMain   ~ 1 + (1 | r | ID),
                        capture    ~ 1 + (1 | r | ID),
                        saccReq    ~ 1 + (1 | r | ID),
                        InhibPro   ~ 1 + (1 | r | ID),
                        InhibReac  ~ 1 + (1 | r | ID),
                        bindingAct ~ 1 + (1 | r | ID),
                        arbBind    ~ 1 + (1 | r | ID),
                        nl = TRUE)

model_th_noGoalSD <- bf(correct | trials(nTrials) ~ PercSpeed - 
                          inhibition * (InhibPro * exp(-exp(InhibReac)*CTI_num)) + 
                          binding * ((bindingAct + bindArb * arbBind) * CTI_num) +
                          bottomup * capture +
                          saccade * saccReq +
                          goalMain * FixDur_num,
                        PercSpeed  ~ 1 + (1 | r | ID),
                        goalMain   ~ 1,
                        capture    ~ 1 + (1 | r | ID),
                        saccReq    ~ 1 + (1 | r | ID),
                        InhibPro   ~ 1 + (1 | r | ID),
                        InhibReac  ~ 1 + (1 | r | ID),
                        bindingAct ~ 1 + (1 | r | ID),
                        arbBind    ~ 1 + (1 | r | ID),
                        nl = TRUE)

model_th_noCapSD <- bf(correct | trials(nTrials) ~ PercSpeed - 
                         inhibition * (InhibPro * exp(-exp(InhibReac)*CTI_num)) + 
                         binding * ((bindingAct + bindArb * arbBind) * CTI_num) +
                         bottomup * capture +
                         saccade * saccReq +
                         goalMain * FixDur_num,
                       PercSpeed  ~ 1 + (1 | r | ID),
                       goalMain   ~ 1 + (1 | r | ID),
                       capture    ~ 1,
                       saccReq    ~ 1 + (1 | r | ID),
                       InhibPro   ~ 1 + (1 | r | ID),
                       InhibReac  ~ 1 + (1 | r | ID),
                       bindingAct ~ 1 + (1 | r | ID),
                       arbBind    ~ 1 + (1 | r | ID),
                       nl = TRUE)

model_th_noSacSD <- bf(correct | trials(nTrials) ~ PercSpeed - 
                         inhibition * (InhibPro * exp(-exp(InhibReac)*CTI_num)) + 
                         binding * ((bindingAct + bindArb * arbBind) * CTI_num) +
                         bottomup * capture +
                         saccade * saccReq +
                         goalMain * FixDur_num,
                       PercSpeed  ~ 1 + (1 | r | ID),
                       goalMain   ~ 1 + (1 | r | ID),
                       capture    ~ 1 + (1 | r | ID),
                       saccReq    ~ 1,
                       InhibPro   ~ 1 + (1 | r | ID),
                       InhibReac  ~ 1 + (1 | r | ID),
                       bindingAct ~ 1 + (1 | r | ID),
                       arbBind    ~ 1 + (1 | r | ID),
                       nl = TRUE)

model_th_noInhProSD <- bf(correct | trials(nTrials) ~ PercSpeed - 
                            inhibition * (InhibPro * exp(-exp(InhibReac)*CTI_num)) + 
                            binding * ((bindingAct + bindArb * arbBind) * CTI_num) +
                            bottomup * capture +
                            saccade * saccReq +
                            goalMain * FixDur_num,
                          PercSpeed  ~ 1 + (1 | r | ID),
                          goalMain   ~ 1 + (1 | r | ID),
                          capture    ~ 1 + (1 | r | ID),
                          saccReq    ~ 1 + (1 | r | ID),
                          InhibPro   ~ 1,
                          InhibReac  ~ 1 + (1 | r | ID),
                          bindingAct ~ 1 + (1 | r | ID),
                          arbBind    ~ 1 + (1 | r | ID),
                          nl = TRUE)

model_th_noInhReSD <- bf(correct | trials(nTrials) ~ PercSpeed - 
                           inhibition * (InhibPro * exp(-exp(InhibReac)*CTI_num)) + 
                           binding * ((bindingAct + bindArb * arbBind) * CTI_num) +
                           bottomup * capture +
                           saccade * saccReq +
                           goalMain * FixDur_num,
                         PercSpeed  ~ 1 + (1 | r | ID),
                         goalMain   ~ 1 + (1 | r | ID),
                         capture    ~ 1 + (1 | r | ID),
                         saccReq    ~ 1 + (1 | r | ID),
                         InhibPro   ~ 1 + (1 | r | ID),
                         InhibReac  ~ 1,
                         bindingAct ~ 1 + (1 | r | ID),
                         arbBind    ~ 1 + (1 | r | ID),
                         nl = TRUE)

model_th_noBindSD <- bf(correct | trials(nTrials) ~ PercSpeed - 
                          inhibition * (InhibPro * exp(-exp(InhibReac)*CTI_num)) + 
                          binding * ((bindingAct + bindArb * arbBind) * CTI_num) +
                          bottomup * capture +
                          saccade * saccReq +
                          goalMain * FixDur_num,
                        PercSpeed  ~ 1 + (1 | r | ID),
                        goalMain   ~ 1 + (1 | r | ID),
                        capture    ~ 1 + (1 | r | ID),
                        saccReq    ~ 1 + (1 | r | ID),
                        InhibPro   ~ 1 + (1 | r | ID),
                        InhibReac  ~ 1 + (1 | r | ID),
                        bindingAct ~ 1,
                        arbBind    ~ 1 + (1 | r | ID),
                        nl = TRUE)

model_th_noArbBindSD <- bf(correct | trials(nTrials) ~ PercSpeed - 
                             inhibition * (InhibPro * exp(-exp(InhibReac)*CTI_num)) + 
                             binding * ((bindingAct + bindArb * arbBind) * CTI_num) +
                             bottomup * capture +
                             saccade * saccReq +
                             goalMain * FixDur_num,
                           PercSpeed  ~ 1 + (1 | r | ID),
                           goalMain   ~ 1 + (1 | r | ID),
                           capture    ~ 1 + (1 | r | ID),
                           saccReq    ~ 1 + (1 | r | ID),
                           InhibPro   ~ 1 + (1 | r | ID),
                           InhibReac  ~ 1 + (1 | r | ID),
                           bindingAct ~ 1 + (1 | r | ID),
                           arbBind    ~ 1,
                           nl = TRUE)

model_th_reduced <- bf(correct | trials(nTrials) ~ PercSpeed - 
                         inhibition * (InhibPro * exp(-InhibReac*CTI_num)) + 
                         binding * ((bindingAct + bindArb * arbBind) * CTI_num) +
                         bottomup * capture +
                         saccade * saccReq +
                         goalMain * FixDur_num,
                       PercSpeed  ~ 1 + (1 | r | ID),
                       goalMain   ~ 1 + (1 | r | ID),
                       capture    ~ 1 + (1 | r | ID),
                       saccReq    ~ 1 + (1 | r | ID),
                       InhibPro   ~ 1 + (1 | r | ID),
                       InhibReac  ~ 1,
                       bindingAct ~ 1 + (1 | r | ID),
                       arbBind    ~ 1 + (1 | r | ID),
                       nl = TRUE)

model_th_final <- bf(correct | trials(nTrials) ~ PercSpeed - 
                       inhibition * (InhibPro * exp(-exp(InhibReac)*CTI_num)) + 
                       binding * ((bindingAct + bindArb * arbBind) * CTI_num) +
                       bottomup * capture +
                       saccade * saccReq +
                       goalMain * FixDur_num,
                     PercSpeed  ~ 1 + (1 | r | ID),
                     goalMain   ~ 1,
                     capture    ~ 1 + (1 | r | ID),
                     saccReq    ~ 1 + (1 | r | ID),
                     InhibPro   ~ 1,
                     InhibReac  ~ 1 + (1 | r | ID),
                     bindingAct ~ 1 + (1 | r | ID),
                     arbBind    ~ 1 + (1 | r | ID),
                     nl = TRUE)

all_model_formulas <- list(saturated = model_sat, 
                           th_full = model_th_full, 
                           noPercSD = model_th_noPercSD, 
                           noGoalSD = model_th_noGoalSD, 
                           noCapSD = model_th_noCapSD, 
                           noSacSD = model_th_noSacSD, 
                           noInhProSD =model_th_noInhProSD, 
                           noInhReSD = model_th_noInhReSD, 
                           noBindSD = model_th_noBindSD,
                           noArbBindSD = model_th_noArbBindSD,
                           reduced = model_th_reduced,
                           th_final = model_th_final)

```

To obtain single covariates for working memory capacity and processing speed, we fitted confirmatory factor models to the proportion correct in working memory tasks, and the drift rate in processing speed tasks and extracted the factor scores of the latent factor capturing the shared variance of the indicators for working memory capacity and processing speed.

```{r Covariates}
fit_MM_PS_drift <- lavaan::sem(model = readLines(here("SEM","Exp9_MM_ProcSpeed.sem")),
                               data = aggData_PS, std.lv = T, std.ov = T, orthogonal = T,
                               missing = "ML")

fit_MM_PS_bound <- lavaan::sem(model = readLines(here("SEM","Exp9_MM_ProcSpeed_bound.sem")),
                               data = aggData_PS, std.lv = T, std.ov = T, orthogonal = T,
                               missing = "ML")

fit_MM_PS_t0 <- lavaan::sem(model = readLines(here("SEM","Exp9_MM_ProcSpeed_t0.sem")),
                            data = aggData_PS, std.lv = T, std.ov = T, orthogonal = T,
                            missing = "ML")

# extract factor scores
PS_scores <- data.frame(v = lavPredict(fit_MM_PS_drift),
                        a = lavPredict(fit_MM_PS_bound),
                        t0 = lavPredict(fit_MM_PS_t0))
PS_scores$ID <- aggData_PS$ID

fit_MM_WMC <- lavaan::sem(model = readLines(here("SEM","Exp9_MM_WMC.sem")),
                          data = aggData_WMC, std.lv = T, std.ov = T, missing = "ML")

# extract factor scores
WMC_scores <- data.frame(lavPredict(fit_MM_WMC))
WMC_scores$ID <- aggData_WMC$ID

COV_scores <- PS_scores %>% full_join(WMC_scores)
agg_data <- agg_data %>% left_join(COV_scores)
colnames(agg_data) <- gsub("_g","",colnames(agg_data))
```

For all model parameters in the GLM, we used moderately informative normal priors centered on zero with a standard deviation of one. Parameters were estimated with four independent MCMC chains retaining 10000 samples for each chain after 2000 warm-up samples.

```{r Priors}
sat_priors <- prior("logistic(0,1)", class = b)
theoretical_priors <- prior("normal(0,1)", class = b, nlpar = PercSpeed) +
  prior("normal(0,1)", class = b, nlpar = goalMain) +
  prior("normal(0,1)", class = b, nlpar = capture) +
  prior("normal(0,1)", class = b, nlpar = saccReq) +
  prior("normal(0,1)", class = b, nlpar = InhibPro) +
  prior("normal(0,1)", class = b, nlpar = InhibReac) +
  prior("normal(0,1)", class = b, nlpar = bindingAct) +
  prior("normal(0,1)", class = b, nlpar = arbBind)
theoretical_priors_reduced <- prior("normal(0,1)", class = b, nlpar = PercSpeed) +
  prior("normal(0,1)", class = b, nlpar = goalMain) +
  prior("normal(0,1)", class = b, nlpar = capture) +
  prior("normal(0,1)", class = b, nlpar = saccReq) +
  prior("normal(0,1)", class = b, nlpar = InhibPro) +
  prior("constant(0)", class = b, nlpar = InhibReac) +
  prior("normal(0,1)", class = b, nlpar = bindingAct) +
  prior("normal(0,1)", class = b, nlpar = arbBind)
```

```{r sampling_settings}
nChains <- 4
warmup_samples <- 2000
postwarmup_samples <- 10000
```

# Results

## Descriptive Statistics

```{r TableDesc, echo=FALSE, fig.align='center', out.width="80%"}
#| label: tbl-descriptivesCTI
#| tab-cap: "Desciptive statistiscs for the proportion correct in the different experimental conditions and each CTI condition."
table_data <- agg_data %>% 
  group_by(Block, CTI_num) %>% 
  summarise(Mean = mean(correct/nTrials),
            SD = sd(correct/nTrials),
            Min = min(correct/nTrials),
            Max = max(correct/nTrials),
            .groups = "drop") %>% 
  mutate(CTI_num = as.factor(round(CTI_num * 1000)))

names(table_data)[which(names(table_data) == "CTI_num")] <- "CTI"

knitr::kable(table_data,digits = 2)
```

```{r TableDesc}
#| label: tbl-descriptivesFixDur
#| tab-cap: "Desciptive statistiscs for the proportion correct in the different experimental conditions and each Fixation duration condition."
table_data <- agg_data %>% 
  group_by(Block, FixDur_num) %>% 
  summarise(Mean = mean(correct/nTrials),
            SD = sd(correct/nTrials),
            Min = min(correct/nTrials),
            Max = max(correct/nTrials),
            .groups = "drop") %>% 
  mutate(FixDur_num = as.factor(round(FixDur_num * 1000 + (mean(unique(data$FixDur))))))

names(table_data)[which(names(table_data) == "FixDur_num")] <- "Fixation Dur."

knitr::kable(table_data,digits = 2)
```

The summary statistics for the proportion of correct responses in the five different blocks for all CTI durations are given in @tbl-descriptivesCTI and for all Fixation Durations in @tbl-descriptivesFixDur. @fig-descriptive displays the average performance across the different conditions and includes performance of each subject in each of the conditions.

```{r FigDesc, echo=FALSE}
plot_data <- data %>%
  dplyr::group_by(ID, Block, bottomup, saccade, inhibition, binding, CTI, CTI_num) %>%
  dplyr::summarise(
    correct = sum(correct),
    nTrials = dplyr::n(),
    .groups = "drop"
  )

desc_plot <- ggplot(data = plot_data,
                    aes(x = as.factor(CTI_num*1000), y = correct/nTrials, color = as.factor(Block), fill = as.factor(Block), 
                        group = as.factor(Block), shape = as.factor(bottomup))) +
  facet_grid(inhibition ~ binding, labeller = label_both) +
  ggplot2::geom_jitter(position = ggplot2::position_jitterdodge(jitter.width = jitter_width, dodge.width = plot_dodge),
                       alpha = point_alpha) +
  stat_summary(position = position_dodge(plot_dodge), fun.data = mean_se) +
  ggplot2::stat_summary(geom = "line", fun = "mean", position = ggplot2::position_dodge(plot_dodge)) +
  geom_hline(yintercept = 0.33, color = "red", linetype = "dashed") +
  labs(x = "Cue-Target Interval (ms)",
       y = "Proportion Correct",
       color = "Block", fill = "Block",
       shape = "Pos Cue = Target",
       title = "Descriptive Plot") +
  coord_cartesian(ylim = c(0,1)) +
  theme_bw() +
  theme(panel.grid.major.x = element_blank())
ggsave(filename = "figures_E2/E2_Descriptives.jpg",desc_plot, dpi = 300, width = 7, height = 6)
```

![Average performance in the different experimental blocks for different CTI durations.](figures_E2/E2_Descriptives.jpg){#fig-descriptive}

@fig-descriptivesCov shows the performance in the working memory capacity and processing speed tasks.

```{r}
#| label: fig-descriptivesCov
#| fig-cap: "Descriptive performance in the working memory capacity and processing speed tasks"
#| fig-subcap:
#|   - "Working Memory Capacity"
#|   - "Processing Speed"
#| layout-ncol: 2
plotDesc_WMC
plotDrift_PS
```

## GLM: Accuracy

```{r FitModel, include=FALSE}
for(i in 1:length(all_model_formulas)) {
  model_name <- names(all_model_formulas)[i]
  model_formula = all_model_formulas[[i]]
  
  if (model_name == "saturated") {
    priors <- sat_priors
  } else if(model_name == "reduced") {
    priors <- theoretical_priors_reduced
  } else {
    priors <- theoretical_priors
  }
  
  fitted_model <- brms::brm(model_formula,
                            data = agg_data,
                            family = model_family,
                            backend = "cmdstanr",
                            chains = nChains,
                            iter = warmup_samples + postwarmup_samples, 
                            warmup = warmup_samples,
                            prior = priors,
                            save_pars = save_pars(all = T),
                            file = paste0("modelFits_E2/fit_E2_", model_name),
                            file_refit = "on_change")
  
  prior_model <- brms::brm(model_formula,
                           data = agg_data,
                           family = model_family,
                           backend = "cmdstanr",
                           chains = nChains,
                           iter = warmup_samples + postwarmup_samples, 
                           warmup = warmup_samples,
                           prior = priors,
                           sample_prior = "only",
                           save_pars = save_pars(all = T),
                           file = paste0("modelFits_E2/fit_E2_", model_name,"_priors"),
                           file_refit = "on_change")
  
  if (!file.exists(paste("modelFits_E2/bridge_E2_", model_name, ".rds", sep = ""))) {
    bridge <- bridge_sampler(fitted_model, cores = 4, repetitions = 10)
    saveRDS(bridge, paste("modelFits_E2/bridge_E2_", model_name, ".rds", sep = ""))
  }
}

rm(fitted_model, prior_model, bridge)
```

```{r BayesFactors_SD}
marginalLL <- list()
for(i in 1:length(all_model_formulas)) {
  model_name <- names(all_model_formulas)[i]
  model_formula = all_model_formulas[[i]]
  marginalLL[[i]] <- readRDS(paste("modelFits_E2/bridge_E2_", model_name, ".rds", sep = ""))
}
names(marginalLL) <- names(all_model_formulas)

noSD_models <- names(marginalLL)[grepl("SD",names(marginalLL))]
bf_noSD <- data.frame(
  sd = noSD_models,
  median_bf = NaN,
  min_bf = NaN,
  max_bf = NaN
)

for(i in 1:length(noSD_models)) {
  bf <- bayes_factor(marginalLL[["th_full"]], marginalLL[[noSD_models[i]]])
  
  bf_noSD$median_bf[i] <- bf$bf_median_based
  bf_noSD$min_bf[i] <- min(bf$bf)
  bf_noSD$max_bf[i] <- max(bf$bf)
}
```

```{r LoadModel, include=FALSE}
fit_E2_sat <- readRDS("modelFits_E2/fit_E2_saturated.rds")

fit_E2_th_full <- readRDS("modelFits_E2/fit_E2_th_full.rds")
fit_E2_th_full_prior <- readRDS("modelFits_E2/fit_E2_th_full_priors.rds")

fit_E2_th_final <- readRDS("modelFits_E2/fit_E2_th_final.rds")
fit_E2_th_final_priors <- readRDS("modelFits_E2/fit_E2_th_final_priors.rds")

# extract fixed effect for theoretical model
fixFX <- round(fixef(fit_E2_th_full),2)

newdata_saturated <- expand.grid(
  ID = unique(agg_data$ID),
  nTrials = 1,
  CTI_num = unique(agg_data$CTI_num),
  Block = unique(agg_data$Block)
)

tidy_pred_saturated <- fit_E2_sat %>% 
  tidybayes::epred_draws(newdata = newdata_saturated, ndraws = 1000) %>% 
  group_by(ID, CTI_num, Block) %>% 
  summarise(predValue = mean(.epred)) %>% 
  left_join(Block2Conds) 

pp_plot_saturated <- ggplot(data = tidy_pred_saturated,
                            aes(x = as.factor(CTI_num*1000), y = predValue, color = as.factor(Block), fill = as.factor(Block), 
                                group = as.factor(Block), shape = as.factor(bottomup))) +
  facet_grid(inhibition ~ binding, labeller = label_both) +
  facet_grid(inhibition ~ binding, labeller = label_both) +
  ggplot2::geom_jitter(position = ggplot2::position_jitterdodge(jitter.width = jitter_width, dodge.width = plot_dodge),
                       alpha = point_alpha) +
  stat_summary(position = position_dodge(plot_dodge), fun.data = mean_se) +
  ggplot2::stat_summary(geom = "line", fun = "mean", position = ggplot2::position_dodge(plot_dodge)) +
  stat_summary(geom = "point", fun = mean, position = position_dodge(plot_dodge),
               data = agg_data, color = "black", shape = "cross",
               aes(x = as.factor(CTI_num*1000), y = correct/nTrials)) +
  geom_hline(yintercept = 0.33, color = "red", linetype = "dashed") +
  labs(x = "Cue-Target Interval (ms)",
       y = "Proportion Correct",
       color = "Block", fill = "Block",
       shape = "Pos Cue = Target",
       title = "Posterior Predictives (Saturated)") +
  coord_cartesian(ylim = c(0,1)) +
  theme_bw() +
  theme(panel.grid.major.x = element_blank())
ggsave(filename = "figures_E2/PostPredictives_Saturated_E2.jpg",pp_plot_saturated, dpi = 300, width = 7, height = 6)

newdata_theoretical <- expand.grid(
  ID = unique(fit_E2_th_final$data$ID),
  nTrials = 1,
  CTI_num = unique(fit_E2_th_final$data$CTI_num),
  FixDur_num = unique(fit_E2_th_final$data$FixDur_num),
  binding = unique(fit_E2_th_final$data$binding),
  inhibition = unique(fit_E2_th_final$data$inhibition),
  saccade = unique(fit_E2_th_final$data$saccade),
  bottomup = unique(fit_E2_th_final$data$bottomup),
  bindArb = unique(fit_E2_th_final$data$bindArb)
) %>% 
  left_join(Block2Conds) %>% 
  filter(!is.na(Block))

tidy_pred_theoretical <- fit_E2_th_full %>% 
  tidybayes::epred_draws(newdata = newdata_theoretical, ndraws = 1000) %>% 
  group_by(ID, CTI_num, FixDur_num, binding, bindArb, inhibition, saccade, bottomup) %>% 
  summarise(predValue = mean(.epred), .groups = "drop") %>%
  group_by(ID, CTI_num, binding, bindArb, inhibition, saccade, bottomup) %>% 
  summarise(predValue = mean(predValue), .groups = "drop") %>%  
  left_join(Block2Conds) %>% 
  filter(!is.na(Block))

pp_plot_theoretical <- ggplot(data = tidy_pred_theoretical,
                              aes(x = as.factor(CTI_num*1000), y = predValue, color = as.factor(Block), fill = as.factor(Block), 
                                  group = as.factor(Block), shape = as.factor(bottomup))) +
  facet_grid(inhibition ~ binding, labeller = label_both) +
  ggplot2::geom_jitter(position = ggplot2::position_jitterdodge(jitter.width = jitter_width, dodge.width = plot_dodge),
                       alpha = point_alpha) +
  ggplot2::stat_summary(geom = "line", fun = "mean", position = ggplot2::position_dodge(plot_dodge)) +
  stat_summary(position = position_dodge(plot_dodge), fun.data = mean_se) +
  stat_summary(geom = "point", fun = mean, position = position_dodge(plot_dodge),
               data = agg_data, color = "black", shape = "cross",
               aes(x = as.factor(CTI_num*1000), y = correct/nTrials)) +
  geom_hline(yintercept = 0.33, color = "red", linetype = "dashed") +
  labs(x = "Cue-Target Interval (in ms)",
       y = "Proportion Correct",
       color = "Block", fill = "Block",
       shape = "Pos Cue = Target",
       title = "Posterior Predictives (Theoretical)") +
  coord_cartesian(ylim = c(0,1))+
  theme_bw() +
  theme(panel.grid.major.x = element_blank())
ggsave(filename = "figures_E2/PostPredictives_theoretical_E2.jpg",pp_plot_theoretical, dpi = 300, width = 7, height = 6)

bf_pars_th_full <- bayestestR::bayesfactor_parameters(fit_E2_th_full, prior = fit_E2_th_full_prior)
bf_inhibreac <- bayes_factor(marginalLL[["noInhReSD"]], marginalLL[["reduced"]])

min_bf_parameters <- min(c(exp(bf_pars_th_full$log_BF[which(bf_pars_th_full$Parameter != "b_InhibReac_Intercept")]), bf_inhibreac$bf_median_based))
```

### Experimental Effects

![](figures_E2/PostPredictives_theoretical_E2.jpg){#fig-predictive}

@fig-predictive shows the posterior predictive estimates from the Bayesian GLM for the different experimental blocks and the changes in performance across the different CTI levels on the proportion correct scale. The theoretical model fits adequately to the observed data, as indicated by the black crosses in the plot overlaying closely with the posterior mean predicted in each condition.

As in Experiment 1, we tested if there is evidence for the different theoretical assumed processes contributing to performance in the manual Anti-Saccade task. A summary of parameter estimates is displayed in @tbl-parameters. All parameters were credibly different from zero, $BF_{10} > `r print_num(min_bf_parameters)`$, which replicates the results from Experiment 1.

```{r ParTable}
#| label: tbl-parameters
#| tab-cap: "Overview of parameter estimates"
rownames(fixFX) <- stringr::str_remove(rownames(fixFX), "_Intercept")
fixFX["InhibReac",]<- exp(fixFX["InhibReac",])

corr_est <- VarCorr(fit_E2_th_full)$ID
sdFX <- round(corr_est$sd,2)
row.names(sdFX) <- stringr::str_remove(row.names(sdFX),"_Intercept")

allFX <- cbind(fixFX, sdFX)
knitr::kable(allFX[,c(1,3:5,7:8)], digits = 2)
```

### Individual differences

```{r}
#| label: tbl-bfSD
#| tab-cap: "Bayes Factors in favor of individual differences in the processes seperated."
# test if there is evidence for individual differences in the different processes
bf_final <- bayes_factor(marginalLL[["th_final"]], marginalLL[["th_full"]])

knitr::kable(bf_noSD, digits = 2)
```

We again tested if there are credible individual differences in the processes dissociated in our theoretical model. For this, we selectively fixed the random effect of one of the processes to zero and tested if this model was favored over a model freely estimating the random effect. These analyses indicated that there was credible evidence for individual differences in all but processes separated in the model (see @tbl-bfSD). Like in Experiment 1, there was evidence against individual differences in goal Maintenance. Also similar to experiment 1, the Bayes Factors for individual difference in proactive inhibition was quite variable, in this experiment this was also the case for individual differences in reactive inhibition. This is potentially due to the reduction of CTI conditions that render the estimation of intial activation eliciting reflexive saccades and its reduction over time more challenging. For consistency with experiment 1, we therefore fixed the random effect of goal maintenance and proactive inhibition to zero. This reduced model fitted better than a model including all random effects, $BF =$ `r printnum(bf_final$bf_median_based, format = "g")`.

Liek for experiment 1, we estimated the correlations between the random effects that were retained in this final model. @tbl-correlations shows the estimated standard deviations of all random effects and the correlations among them. Generally, correlations between random effects were small, most $|r_s| < .30$, except for correlations between random effects for binding ability and costs of arbitrary bindings with each other, $r = .66$, and with reactive inhibition, $r_s = .44 - .47$, as well as individual differences in the automatic capture of attention by the cue, $r = .49$. Given the differences between experiment 1 and 2 with respect to overall proportion correct, these correlations should be interpreted with caution and need replication in a larger sample to obtain stable estimates for the relationship between the theoretically dissociated processes.

```{r CorrTable}
#| label: tbl-correlations
#| tab-cap: "Correlations between random effects. Values on the diagonal represent the posterior estimates of the standard deviation of each random effect."
corr_est <- VarCorr(fit_E2_th_final)$ID

cormat <- matrix(NA, nrow = nrow(corr_est$sd), ncol = nrow(corr_est$sd))

for (i in 1:dim(corr_est$cor)[3]){
  cormat[i,] <- corr_est$cor[,"Estimate",i]
}

rownames(cormat) <- stringr::str_remove(dimnames(corr_est$cor)[[3]],"_Intercept")
colnames(cormat) <- stringr::str_remove(dimnames(corr_est$cor)[[3]],"_Intercept")
diag(cormat) <- corr_est$sd[,"Estimate"]
cormat <- round(cormat,2)
cormat[upper.tri(cormat)] <- ""
knitr::kable(cormat, digits = 2)
```

### Validity of the Anti-Saccade Task

@fig-validity shows correlations between the random effects of processes separated in the GLM with the observed performance in the different experimental blocks. These correlations capture to what extend performance in one of the experimental blocks is a valid indicator for the processes. A process pure indicator would only correlate with one of the process measures. As is evident from the figure and replicating the results from experiment 1, none of the experimental blocks is a truly process pure indicator for a single process. With respect to the typical use of the anti-saccade task (using a CTI of 50ms), experiment 2 indicated that it is measuring at least three processes as we found in experiment 1: sensory discrimination, the speed of filtering automatic activation, and binding ability. The contribution of binding ability in this experiment was actually even a little stronger than that of perceptual speed. This is potentially due to the adaptation of the font size that reduced the transient onset signal of the target letter and required that participants performed controlled saccades to actually be able to detect which target letter was shown.

```{r}
#| label: fig-validity
#| fig-cap: "Validity estimates of performance in the different conditions for the seperated processes."
agg_data_validity <- data %>%
  dplyr::group_by(ID, Block, CTI_num) %>%
  dplyr::summarise(
    pC = sum(correct)/n(),
    .groups = "drop"
  )

relEst_validity <- data |> 
  group_by(ID, Block, CTI_num) |>
  mutate(OddEven = ifelse(1:n() %% 2 == 0, "even","odd")) |> 
  ungroup() |> group_by(ID, Block, CTI_num, OddEven) |>
  summarise(propCorr = sum(correct)/n(), .groups = "drop") |> 
  tidyr::pivot_wider(names_from = OddEven, values_from = propCorr) |>
  group_by(Block, CTI_num) |> 
  summarise(relEst = cor(odd, even, use = "complete.obs"),
            relEst_corr = (2*relEst)/(1+relEst))

randFX_draws <- fit_E2_th_final %>% 
  tidybayes::gather_draws(r_ID__PercSpeed[ID,],
                          r_ID__capture[ID,],
                          r_ID__saccReq[ID,],
                          r_ID__InhibReac[ID,], 
                          r_ID__bindingAct[ID,],
                          r_ID__arbBind[ID,],
                          ndraws = 100) %>% 
  mutate(.variable = stringr::str_remove(.variable, "r_ID__"))

randFX_draws <- randFX_draws %>% 
  tidyr::pivot_wider(names_from = c(.variable),
                     values_from = .value)

df_validity = expand.grid(
  ID = unique(agg_data_validity$ID),
  Block = unique(agg_data_validity$Block),
  CTI_num = unique(agg_data_validity$CTI_num),
  .chain = unique(randFX_draws$.chain),
  .iteration = unique(randFX_draws$.iteration),
  .draw = unique(randFX_draws$.draw)
) |> left_join(randFX_draws, by = c("ID",".chain",".draw",".iteration")) |> 
  left_join(agg_data_validity, by = c("ID","Block","CTI_num"))



df_cor <- df_validity %>% 
  group_by(Block, CTI_num, .draw) %>% 
  summarise(
    PercSpeed = cor(pC, PercSpeed, use = "complete.obs"),
    InhibReac = cor(pC, InhibReac, use = "complete.obs"),
    Binding = cor(pC, bindingAct, use = "complete.obs"),
    arbBind = cor(pC, arbBind, use = "complete.obs"),
    Capture = cor(pC, capture, use = "complete.obs"),
    Saccade = cor(pC, saccReq, use = "complete.obs"),
    .groups = "drop") %>% 
  tidyr::pivot_longer(cols = c(PercSpeed, InhibReac, Binding, arbBind, Capture, Saccade)) %>% 
  left_join(relEst_validity) |> 
  # mutate(value = value/sqrt(relEst_corr)) |> 
  group_by(Block, CTI_num, name) %>% 
  summarise(
    mean = mean(value),
    CIlow = quantile(value, probs = 0.025),
    CIhigh = quantile(value, probs = 0.975)
  )

df_cor$process = "yes"

df_cor[which(df_cor$name == "InhibReac"),]$process <- ifelse(
  df_cor[which(df_cor$name == "InhibReac"),]$Block %in% inhib_blocks, "yes", "no")
df_cor[which(df_cor$name == "Binding"),]$process <- ifelse(
  df_cor[which(df_cor$name == "Binding"),]$Block %in% bind_blocks, "yes", "no")
df_cor[which(df_cor$name == "arbBind"),]$process <- ifelse(
  df_cor[which(df_cor$name == "arbBind"),]$Block %in% bind_blocks, "yes", "no")
df_cor[which(df_cor$name == "Capture"),]$process <- ifelse(
  df_cor[which(df_cor$name == "Capture"),]$Block %in% bottomup_blocks, "yes", "no")
df_cor[which(df_cor$name == "Saccade"),]$process <- ifelse(
  df_cor[which(df_cor$name == "Saccade"),]$Block %in% saccade_blocks, "yes", "no")

df_cor$name <- factor(df_cor$name, 
                      levels = c("PercSpeed", "Capture","Saccade",
                                 "InhibReac", "Binding", "arbBind"))
levels(df_cor$name) <- c("Perc. Speed", "Bottom-Up Gudiance","Saccade", 
                         "Inhibition: Reactive", "Binding", "ΔB")

plot_validity <- ggplot(data = df_cor,
                        aes(x = as.factor(CTI_num*1000), y = mean, ymin = CIlow, ymax = CIhigh, color = Block, shape = process, alpha = process)) +
  geom_point(position = position_dodge(0.5), size =2) +
  geom_errorbar(width = 0, position = position_dodge(0.5), linewidth = 1) +
  facet_wrap(~name) +
  geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
  scale_alpha_discrete(range = c(1/3,1)) +
  labs(x = "Cue-Target Interval (ms)", y = "Validity (Correlation: Process with Prop. Corr)",
       shape = "Process\n included:", alpha = "Process\n included:") +
  coord_cartesian(ylim = c(-0.5,1)) +
  theme_bw() +
  theme(panel.grid.major.x = element_blank())

ggsave(filename = "figures_E2/Validity_E2.jpg",plot_validity, dpi = 300, width = 7, height = 6)
knitr::include_graphics("figures_E2/Validity_E2.jpg")
```

## Relationship to Covariates

```{r}
#| label: fig-covcorr
#| fig-cap: "Correlations of average performance in the different experimental blocks of the manual anti-saccade task with working memory capacity (WMC) and processing speed (PS). The points indicate the correlation coefficient and error bars the 95% confindence interval."
relEst_SaccTask <- data |> 
  mutate(OddEven = ifelse(trial %% 2 == 0, "even","odd")) |> 
  group_by(ID, Block, OddEven) |>
  summarise(propCorr = sum(correct)/n(), .groups = "drop") |> 
  tidyr::pivot_wider(names_from = OddEven, values_from = propCorr) |>
  group_by(Block) |> 
  summarise(relEst = cor(odd, even, use = "complete.obs"),
            relEst_corr = (2*relEst)/(1+relEst))

df_corr_descriptive <- data %>%
  dplyr::group_by(ID, Block) %>%
  dplyr::summarise(
    correct = sum(correct),
    nTrials = dplyr::n(),
    .groups = "drop"
  ) |> left_join(COV_scores) |> 
  group_by(Block) |> 
  summarise(
    r_WMC_mean = cor(WMC_g, correct/nTrials, use = "complete.obs"),
    r_PS_mean = cor(v, correct/nTrials, use = "complete.obs"),
    n_WMC = n() - sum(is.na(WMC_g)),
    n_PS = n() - sum(is.na(v))
  ) |> 
  left_join(relEst_SaccTask) |> 
  mutate(
    r_WMC_relCor = r_WMC_mean/sqrt(relEst_corr),
    r_PS_relCor = r_PS_mean/sqrt(relEst_corr),
    r_WMC_mean_upper = tanh(atanh(r_WMC_mean) + qnorm(.975) * (1/sqrt(n_WMC))),
    r_WMC_mean_lower = tanh(atanh(r_WMC_mean) + qnorm(.025) * (1/sqrt(n_WMC))),
    r_PS_mean_upper = tanh(atanh(r_PS_mean) + qnorm(.975) * (1/sqrt(n_PS))),
    r_PS_mean_lower = tanh(atanh(r_PS_mean) + qnorm(.025) * (1/sqrt(n_PS))),
    r_WMC_relCor_upper = tanh(atanh(r_WMC_relCor) + qnorm(.975) * (1/sqrt(n_WMC))),
    r_WMC_relCor_lower = tanh(atanh(r_WMC_relCor) + qnorm(.025) * (1/sqrt(n_WMC))),
    r_PS_relCor_upper = tanh(atanh(r_PS_relCor) + qnorm(.975) * (1/sqrt(n_PS))),
    r_PS_relCor_lower = tanh(atanh(r_PS_relCor) + qnorm(.025) * (1/sqrt(n_PS)))
  ) |> 
  tidyr::pivot_longer(cols = c(r_WMC_mean, r_PS_mean, r_WMC_mean_upper, r_WMC_mean_lower, r_PS_mean_upper, r_PS_mean_lower,
                               r_WMC_relCor, r_PS_relCor, r_WMC_relCor_upper, r_WMC_relCor_lower, r_PS_relCor_upper, r_PS_relCor_lower), 
                      names_to = "Covariate", values_to = "Correlation") |> 
  mutate(pred = stringr::str_split_i(Covariate, "_", 2),
         type = stringr::str_split_i(Covariate, "_", 3),
         stat = stringr::str_split_i(Covariate, "_", 4),
         stat = case_when(is.na(stat) ~ "point",
                          TRUE ~ stat)) |> 
  select(Block, pred, type, stat, Correlation) |>
  tidyr::pivot_wider(names_from = c(stat), values_from = Correlation) |>
  left_join(Block2Conds)
df_corr_descriptive$pred <- as.factor(df_corr_descriptive$pred)


df_corr_descriptive$binding <- as.factor(df_corr_descriptive$binding)
levels(df_corr_descriptive$binding) <- c("no", "yes")

plot_cor_descriptive <- ggplot(df_corr_descriptive |> filter(type == "relCor"),
                               aes(y = point, x = as.factor(binding), ymin = lower, ymax = upper, color = Block)) +
  facet_wrap(~ pred) +
  geom_point(position = position_dodge(0.25), size = 2) +
  geom_errorbar(width = 0, position = position_dodge(0.25)) +
  labs(y = "Correlation", x = "Binding") +
  geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
  theme_bw() +
  theme(panel.grid.major.x = element_blank())

ggsave(filename = "figures_E2/DescCorrelation_E2.jpg",plot_cor_descriptive, dpi = 300, width = 6, height = 4)
knitr::include_graphics("figures_E2/DescCorrelation_E2.jpg")
```

In @fig-covcorr the correlations of the average performance in the different experimental blocks of the manual anti-saccade task with the two covariates, working memory capacity (WMC) and processing speed (PS) are shown. As indicated by the 95% confidence intervals, the correlations with both covariates are all significantly different from zero for all experimental. Although this replicates previous studies that found correlations between performance in the manual anti-saccade task, the results also indicate that most likely processes shared between all tasks are underlying the relationship between performance in the anti-saccade task with the covariates. Otherwise, only performance in the anti-saccade block should correlate with the covariate.

### Relationship of the theoretically assumed processes with WMC & PS

As a preliminary estimate for relationships between the different processes we dissociated in the manual saccade task with WMC and processing speed, we computed correlations between the random effects estimated from the Bayesian GLM model and the latent factor scores extracted from the confirmatory factor models. @tbl-covcorr shows these correlations. These correlations indicate that WMC and PS are primarly correlated with individual differences in the speed of detecting the target letter (PercSpeed), and individual differences in the ability to use the cue location or color to performed controlled saccades towards the location the target appears in (Binding & arbBind). The correlations with the other processes are negligible.

```{r}
#| label: tbl-covcorr
#| tab-cap: "Overview of parameter estimates"
randFX <- ranef(fit_E2_th_final)$ID

df_randFX <- data.frame(
  ID = as.numeric(row.names(randFX[,,"PercSpeed_Intercept"])),
  PercSpeed = randFX[,"Estimate","PercSpeed_Intercept"],
  InhibReac = randFX[,"Estimate","InhibReac_Intercept"],
  Binding = randFX[,"Estimate","bindingAct_Intercept"],
  arbBind = randFX[,"Estimate","arbBind_Intercept"],
  Saccade = randFX[,"Estimate","saccReq_Intercept"],
  bottomUp = randFX[,"Estimate","capture_Intercept"]
)

df_randFX <- df_randFX %>% left_join(COV_scores)
covmat_pred <- round(cor(df_randFX[,c(2:8,11)], use = "complete.obs"),2)
covmat_pred[upper.tri(covmat_pred)] <- ""
knitr::kable(covmat_pred[7:8,1:6], digits = 2)
```

```{r Covariate_formulas}
cov_formulas <- list(
  WMC_all = bf(correct | trials(nTrials) ~ PercSpeed - 
                 inhibition * (InhibPro * exp(-exp(InhibReac)*CTI_num)) + 
                 binding * ((bindingAct + bindArb * arbBind) * CTI_num) +
                 bottomup * capture +
                 saccade * saccReq +
                 goalMain * FixDur_num,
               PercSpeed  ~ 1 + WMC + (1 | r | ID),
               goalMain   ~ 1,
               capture    ~ 1 + WMC + (1 | r | ID),
               saccReq    ~ 1 + WMC + (1 | r | ID),
               InhibPro   ~ 1,
               InhibReac  ~ 1 + WMC + (1 | r | ID),
               bindingAct ~ 1 + WMC + (1 | r | ID),
               arbBind    ~ 1 + WMC + (1 | r | ID),
               nl = TRUE),
  WMC_SpeedBind = bf(correct | trials(nTrials) ~ PercSpeed - 
                       inhibition * (InhibPro * exp(-exp(InhibReac)*CTI_num)) + 
                       binding * ((bindingAct + bindArb * arbBind) * CTI_num) +
                       bottomup * capture +
                       saccade * saccReq +
                       goalMain * FixDur_num,
                     PercSpeed  ~ 1 + WMC + (1 | r | ID),
                     goalMain   ~ 1,
                     capture    ~ 1 + (1 | r | ID),
                     saccReq    ~ 1 + (1 | r | ID),
                     InhibPro   ~ 1,
                     InhibReac  ~ 1 + (1 | r | ID),
                     bindingAct ~ 1 + WMC + (1 | r | ID),
                     arbBind    ~ 1 + WMC + (1 | r | ID),
                     nl = TRUE),
  WMC_SpeedBindInhib = bf(correct | trials(nTrials) ~ PercSpeed - 
                            inhibition * (InhibPro * exp(-exp(InhibReac)*CTI_num)) + 
                            binding * ((bindingAct + bindArb * arbBind) * CTI_num) +
                            bottomup * capture +
                            saccade * saccReq +
                            goalMain * FixDur_num,
                          PercSpeed  ~ 1 + WMC + (1 | r | ID),
                          goalMain   ~ 1,
                          capture    ~ 1 + (1 | r | ID),
                          saccReq    ~ 1 + (1 | r | ID),
                          InhibPro   ~ 1,
                          InhibReac  ~ 1 + WMC + (1 | r | ID),
                          bindingAct ~ 1 + WMC + (1 | r | ID),
                          arbBind    ~ 1 + WMC + (1 | r | ID),
                          nl = TRUE),
  PS_all = bf(correct | trials(nTrials) ~ PercSpeed - 
                inhibition * (InhibPro * exp(-exp(InhibReac)*CTI_num)) + 
                binding * ((bindingAct + bindArb * arbBind) * CTI_num) +
                bottomup * capture +
                saccade * saccReq +
                goalMain * FixDur_num,
              PercSpeed  ~ 1 + v + (1 | r | ID),
              goalMain   ~ 1,
              capture    ~ 1 + v + (1 | r | ID),
              saccReq    ~ 1 + v + (1 | r | ID),
              InhibPro   ~ 1,
              InhibReac  ~ 1 + v + (1 | r | ID),
              bindingAct ~ 1 + v + (1 | r | ID),
              arbBind    ~ 1 + v + (1 | r | ID),
              nl = TRUE),
  PS_SpeedBind = bf(correct | trials(nTrials) ~ PercSpeed - 
                      inhibition * (InhibPro * exp(-exp(InhibReac)*CTI_num)) + 
                      binding * ((bindingAct + bindArb * arbBind) * CTI_num) +
                      bottomup * capture +
                      saccade * saccReq +
                      goalMain * FixDur_num,
                    PercSpeed  ~ 1 + v + (1 | r | ID),
                    goalMain   ~ 1,
                    capture    ~ 1 + (1 | r | ID),
                    saccReq    ~ 1 + (1 | r | ID),
                    InhibPro   ~ 1,
                    InhibReac  ~ 1 + (1 | r | ID),
                    bindingAct ~ 1 + v + (1 | r | ID),
                    arbBind    ~ 1 + v + (1 | r | ID),
                    nl = TRUE),
  PS_SpeedBindInhib = bf(correct | trials(nTrials) ~ PercSpeed - 
                           inhibition * (InhibPro * exp(-exp(InhibReac)*CTI_num)) + 
                           binding * ((bindingAct + bindArb * arbBind) * CTI_num) +
                           bottomup * capture +
                           saccade * saccReq +
                           goalMain * FixDur_num,
                         PercSpeed  ~ 1 + v + (1 | r | ID),
                         goalMain   ~ 1,
                         capture    ~ 1 + (1 | r | ID),
                         saccReq    ~ 1 + (1 | r | ID),
                         InhibPro   ~ 1,
                         InhibReac  ~ 1 + v + (1 | r | ID),
                         bindingAct ~ 1 + v + (1 | r | ID),
                         arbBind    ~ 1 + v + (1 | r | ID),
                         nl = TRUE)
)

for(i in 1:length(cov_formulas)) {
  model_name <- names(cov_formulas)[i]
  model_formula = cov_formulas[[i]]
  
  priors <- theoretical_priors
  
  fitted_model <- brms::brm(model_formula,
                            data = agg_data,
                            family = model_family,
                            backend = "cmdstanr",
                            chains = nChains,
                            iter = warmup_samples + postwarmup_samples, 
                            warmup = warmup_samples,
                            prior = priors,
                            save_pars = save_pars(all = T),
                            file = paste0("modelFits_E2/fit_E2_", model_name),
                            file_refit = "on_change")
  
  prior_model <- brms::brm(model_formula,
                           data = agg_data,
                           family = model_family,
                           backend = "cmdstanr",
                           chains = nChains,
                           iter = warmup_samples + postwarmup_samples, 
                           warmup = warmup_samples,
                           prior = priors,
                           save_pars = save_pars(all = T),
                           sample_prior = "only",
                           file = paste0("modelFits_E2/fit_E2_", model_name,"_prior"),
                           file_refit = "on_change")
  
  if (!file.exists(paste("modelFits_E2/bridge_E2_", model_name, ".rds", sep = ""))) {
    bridge <- bridge_sampler(fitted_model, cores = 4, repetitions = 10)
    saveRDS(bridge, paste("modelFits_E2/bridge_E2_", model_name, ".rds", sep = ""))
  }
}
```

```{r BayesFactors_Covariates}
marginalLL_cov <- list()
for(i in 1:length(cov_formulas)) {
  model_name <- names(cov_formulas)[i]
  model_formula = cov_formulas[[i]]
  marginalLL_cov[[i]] <- readRDS(paste("modelFits_E2/bridge_E2_", model_name, ".rds", sep = ""))
}
names(marginalLL_cov) <- names(cov_formulas)

bf_covariates <- data.frame(
  reference = character(12),
  comparison = character(12),
  median_bf = numeric(12),
  min_bf = numeric(12),
  max_bf = numeric(12)
)

i <- 1
for(cov in c("WMC","PS")) {
  cov_models <- grep(cov, names(marginalLL_cov), value = T)
  
  for(model in cov_models){
    bf <- bayes_factor(marginalLL[["th_final"]], marginalLL_cov[[model]])
    
    bf_covariates$reference[i] <- "th_final"
    bf_covariates$comparison[i] <- model
    
    bf_covariates$median_bf[i] <- bf$bf_median_based
    bf_covariates$min_bf[i] <- min(bf$bf)
    bf_covariates$max_bf[i] <- max(bf$bf)
    
    i <- i + 1
    if(which(model == cov_models) != length(cov_models)) {
      for(j in (which(model == cov_models)+1):length(cov_models)){
        refernce_model = model
        comparison_model = cov_models[j]
        
        bf <- bayes_factor(marginalLL_cov[[refernce_model]], marginalLL_cov[[comparison_model]])
        
        bf_covariates$reference[i] <- refernce_model
        bf_covariates$comparison[i] <- comparison_model
        
        bf_covariates$median_bf[i] <- bf$bf_median_based
        bf_covariates$min_bf[i] <- min(bf$bf)
        bf_covariates$max_bf[i] <- max(bf$bf)
        
        i <- i + 1
      }
    }
  }
}
```

```{r}
fit_E2_WMC_all <- readRDS("modelFits_E2/fit_E2_WMC_all.rds")
fit_E2_WMC_all_priors <- readRDS("modelFits_E2/fit_E2_WMC_all_prior.rds")

bf_WMC_parameters <- bayestestR::bayesfactor_parameters(fit_E2_WMC_all, prior = fit_E2_WMC_all_priors)
bf_WMC_parameters <- bf_WMC_parameters[grepl("WMC",bf_WMC_parameters$Parameter),1:2]
bf_WMC_parameters$BF <- exp(bf_WMC_parameters$log_BF)
bf_WMC_parameters$Parameter <- gsub("b_", "", bf_WMC_parameters$Parameter)

fit_E2_PS_all <- readRDS("modelFits_E2/fit_E2_PS_all.rds")
fit_E2_PS_all_priors <- readRDS("modelFits_E2/fit_E2_PS_all_prior.rds")

bf_PS_parameters <- bayestestR::bayesfactor_parameters(fit_E2_PS_all, prior = fit_E2_PS_all_priors)
bf_PS_parameters <- bf_PS_parameters[grepl("v",bf_PS_parameters$Parameter),1:2]
bf_PS_parameters$BF <- exp(bf_PS_parameters$log_BF)
bf_PS_parameters$Parameter <- gsub("b_", "", bf_PS_parameters$Parameter)
```

To evaluate which of these relationships differs credibly from zero, we entered the factor scores of WMC and processing speed as covariates into the Bayesian GLM. For WMC as a covariate, the posterior credibility intervals, indicated a positive relationship between WMC and perceptual speed as well as the binding strength (see @tbl-relationshipWMC). However, Bayes Factors indicated inconclusive evidence for the relationship between WMC and perceptual speed, but strong evidence for the relationship between WMC and binding activity. @fig-relationshipsWMC illustrates the relationship of WMC with the dissociated processes of the GLM.

```{r}
#| label: tbl-relationshipWMC
#| tab-cap: "Unstandardized parameters estimates for the relationship for the relationship of WMC and and the dissociated processes in the manual anti-saccade task"
fixFX_WMC <- fixef(fit_E2_WMC_all)
WMC_cols <- grepl("_WMC",rownames(fixFX_WMC))
fixFX_WMC <- as.data.frame(fixFX_WMC[WMC_cols,c("Estimate","Q2.5","Q97.5")])
fixFX_WMC$Parameter <- rownames(fixFX_WMC)

fixFX_WMC <- fixFX_WMC |> left_join(bf_WMC_parameters, by = "Parameter") |> 
  select(Parameter, Estimate, Q2.5, Q97.5, BF)
knitr::kable(fixFX_WMC, digits = 2)
```

```{r}
#| label: fig-relationshipsWMC
#| fig-cap: "Relationship between the processes dissociated in the Manual Anti-Saccade task and WMC"
#| fig-subcap:
#|   - "Perceptual Speed"
#|   - "Bottom Up Capture" 
#|   - "Saccade Required"
#|   - "Inhibition: Reactive"
#|   - "Binding"
#|   - "Binding: Arbitrary" 
#| layout-ncol: 2
#| layout-nrow: 3
conditional_effects(fit_E2_WMC_all, nlpar = "PercSpeed", effect = "WMC")
conditional_effects(fit_E2_WMC_all, nlpar = "capture", effect = "WMC")
conditional_effects(fit_E2_WMC_all, nlpar = "saccReq", effect = "WMC")
conditional_effects(fit_E2_WMC_all, nlpar = "InhibReac", effect = "WMC")
conditional_effects(fit_E2_WMC_all, nlpar = "bindingAct", effect = "WMC")
conditional_effects(fit_E2_WMC_all, nlpar = "arbBind", effect = "WMC")
```

For processing speed, posterior credibility intervals indicated a positive relationship with Baseline performance as well as binding activity (see @tbl-relationshipPS). In this case, Bayes Factors indicated inconclusive evidence for the relationship with Baseline performance and strong evidence for the relationship with binding activity. @fig-relationshipsPS illustrates the relationship of processing speed with the dissociated processes of the GLM.

```{r}
#| label: tbl-relationshipPS
#| tab-cap: "Unstandardized parameters estimates for the relationship of processing speed (drift rate: v) and the dissociated processes in the manual anti-saccade task"
fixFX_PS <- fixef(fit_E2_PS_all)
PS_cols <- grepl("_v",rownames(fixFX_PS))
fixFX_PS <- as.data.frame(fixFX_PS[PS_cols,c("Estimate","Q2.5","Q97.5")])
fixFX_PS$Parameter <- rownames(fixFX_PS)

fixFX_PS <- fixFX_PS |> left_join(bf_PS_parameters, by = "Parameter") |> 
  select(Parameter, Estimate, Q2.5, Q97.5, BF)
knitr::kable(fixFX_PS, digits = 2)
```

```{r}
#| label: fig-relationshipsPS
#| fig-cap: "Relationship between the processes dissociated in the Manual Anti-Saccade task and processing speed (measured with drift rate v)"
#| fig-subcap:
#|   - "Perceptual Speed"
#|   - "Bottom Up Capture" 
#|   - "Saccade Required"
#|   - "Inhibition: Reactive"
#|   - "Binding"
#|   - "Binding: Arbitrary" 
#| layout-ncol: 2
#| layout-nrow: 3
conditional_effects(fit_E2_PS_all, nlpar = "PercSpeed", effect = "v")
conditional_effects(fit_E2_PS_all, nlpar = "capture", effect = "v")
conditional_effects(fit_E2_PS_all, nlpar = "saccReq", effect = "v")
conditional_effects(fit_E2_PS_all, nlpar = "InhibReac", effect = "v")
conditional_effects(fit_E2_PS_all, nlpar = "bindingAct", effect = "v")
conditional_effects(fit_E2_PS_all, nlpar = "arbBind", effect = "v")
```
